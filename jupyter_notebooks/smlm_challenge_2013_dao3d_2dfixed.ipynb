{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze one of the datasets from the 2013 SMLM challenge with 3D-DAOSTORM\n",
    "\n",
    "In this example, we're analyzing a simulated dataset that is 2D, so we'll use the 2D fixed PSF model in 3D-DAOSTORM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the directory\n",
    "Create an empty directory somewhere on your computer and tell Python to go to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/home/hbabcock/Data/storm_analysis/jy_testing/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the dataset from the 2013 SMLM challenge website\n",
    "\n",
    "The dataset we'll use is [here](http://bigwww.epfl.ch/smlm/challenge2013/datasets/Bundled_Tubes_High_Density/index.html). This is the \"Bundled Tubes High Density\" dataset.\n",
    "\n",
    "You'll need to download the \"sequence.zip\" file to the above directory and the unzip it. Look for the \"Download all frames\" button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tif movie from the tif images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tifffile\n",
    "\n",
    "tif_files = glob.glob(os.path.join(\"sequence\", \"*.tif\"))\n",
    "\n",
    "with tifffile.TiffWriter(\"movie.tif\") as tf:\n",
    "    for fname in sorted(tif_files):\n",
    "        image = tifffile.imread(fname)\n",
    "        tf.save(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an XML file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import storm_analysis.sa_library.parameters as parameters\n",
    "\n",
    "params = parameters.ParametersDAO()\n",
    "\n",
    "# Analyze the whole movie.\n",
    "params.setAttr(\"max_frame\", \"int\", -1)    \n",
    "params.setAttr(\"start_frame\", \"int\", -1)\n",
    "\n",
    "params.setAttr(\"background_sigma\", \"float\", 8.0)\n",
    "\n",
    "# These were specified on the website for this dataset.\n",
    "params.setAttr(\"camera_gain\", \"float\", 1.0)\n",
    "params.setAttr(\"camera_offset\", \"float\", 100.0)\n",
    "\n",
    "params.setAttr(\"find_max_radius\", \"int\", 5)\n",
    "params.setAttr(\"foreground_sigma\", \"float\", 1.0)\n",
    "params.setAttr(\"iterations\", \"int\", 20)\n",
    "params.setAttr(\"model\", \"string\", \"2dfixed\")\n",
    "params.setAttr(\"pixel_size\", \"float\", 100.0)\n",
    "params.setAttr(\"roi_size\", \"int\", 9)\n",
    "\n",
    "# Convert from FWHM in nanometers to sigma in pixels.\n",
    "params.setAttr(\"sigma\", \"float\", 258.21/(100.0 * 2.355))\n",
    "params.setAttr(\"threshold\", \"float\", 6)\n",
    "\n",
    "# Don't do tracking.\n",
    "params.setAttr(\"radius\", \"float\", \"0\")\n",
    "params.setAttr(\"descriptor\", \"string\", \"1\")\n",
    "\n",
    "# Don't do drift-correction.\n",
    "params.setAttr(\"drift_correction\", \"int\", 0)\n",
    "\n",
    "params.toXMLFile(\"analysis.xml\", pretty = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import storm_analysis.daostorm_3d.mufit_analysis as mfit\n",
    "\n",
    "# Delete any stale results.\n",
    "if os.path.exists(\"movie.hdf5\"):\n",
    "    os.remove(\"movie.hdf5\")\n",
    "    \n",
    "%time mfit.analyze(\"movie.tif\", \"movie.hdf5\", \"analysis.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference results:\n",
    "\n",
    "```\n",
    "Added 46444\n",
    "   4708 peak finding iterations.\n",
    "\n",
    "   0 fits reset due to Cholesky failure.\n",
    "   14 fits reset due to image margin.\n",
    "   677 fits reset due to negative value in fit function.\n",
    "   115 fits reset due to negative height.\n",
    "   534072 fits reset due to non-decreasing error (LM).\n",
    "   0 fits did not converge.\n",
    "   17 fits were lost.\n",
    "   415 peaks lost to proximity filter.\n",
    "   244 peaks lost to low significance.\n",
    "   6711697 fitting iterations.\n",
    "\n",
    "Tracking.\n",
    "\n",
    "Checking z values.\n",
    "\n",
    "Analysis complete\n",
    "CPU times: user 55 s, sys: 171 ms, total: 55.1 s\n",
    "Wall time: 55 s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check analysis of a single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import storm_analysis.jupyter_examples.overlay_image as overlay_image\n",
    "overlay_image.overlayImage(\"movie.tif\", \"movie.hdf5\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an image of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "import storm_analysis.sa_utilities.hdf5_to_image as h5_image\n",
    "\n",
    "sr_im = h5_image.render2DImage(\"movie.hdf5\", scale = 4, sigma = 1)\n",
    "\n",
    "pyplot.figure(figsize = (8, 8))\n",
    "pyplot.imshow(sr_im, cmap = \"gray\")\n",
    "pyplot.title(\"SR Image\")\n",
    "pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
